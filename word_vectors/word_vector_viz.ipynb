{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94363c7d-1f36-46e7-b2c0-66168261c4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the interactive Tools for Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "\n",
    "# Get tools to download files and load them \n",
    "import pickle\n",
    "import urllib.request\n",
    "from os.path import exists as check_path\n",
    "from os import makedirs\n",
    "\n",
    "# Get tools to performe analysis\n",
    "import numpy as np\n",
    "from heapq import heappushpop\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b6466d8-3112-405f-b103-260958d63650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files_from_github(file_target_dir):\n",
    "    main_url = 'https://raw.githubusercontent.com/Goussha/word-vector-visualization/master/'\n",
    "    if not check_path(file_target_dir):\n",
    "        makedirs(file_target_dir)\n",
    "    \n",
    "    urls = [main_url+'file{}.p'.format(x) for x in range(1,9)]\n",
    "    file_names = [file_target_dir+'file{}.p'.format(x) for x in range(1,9)]\n",
    "    for file_name, url in zip(file_names, urls):\n",
    "        if not check_path(file_name):\n",
    "            print (\"Downloading file: \",file_name)\n",
    "            filename, headers = urllib.request.urlretrieve(url, filename=file_name)\n",
    "        else:\n",
    "            print('Allready exists: {}'.format(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d542a48-9985-4e20-b1a3-b2c8120eeb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word2vecfiles(file_target_dir):\n",
    "    word_dict_loded = {}\n",
    "    for file_num in range(1,9):\n",
    "        full_file_name = file_target_dir+'file{}.p'.format(file_num)\n",
    "        print('Loading file: {}'.format(full_file_name))\n",
    "        with open(full_file_name, 'rb') as fp:\n",
    "            data = pickle.load(fp)\n",
    "        word_dict_loded.update(data)\n",
    "    return word_dict_loded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bd09e01-a286-443d-8138-f11426f3b17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file:  ./tmp/file1.p\n",
      "Downloading file:  ./tmp/file2.p\n",
      "Downloading file:  ./tmp/file3.p\n",
      "Downloading file:  ./tmp/file4.p\n",
      "Downloading file:  ./tmp/file5.p\n",
      "Downloading file:  ./tmp/file6.p\n",
      "Downloading file:  ./tmp/file7.p\n",
      "Downloading file:  ./tmp/file8.p\n",
      "Loading file: ./tmp/file1.p\n",
      "Loading file: ./tmp/file2.p\n",
      "Loading file: ./tmp/file3.p\n",
      "Loading file: ./tmp/file4.p\n",
      "Loading file: ./tmp/file5.p\n",
      "Loading file: ./tmp/file6.p\n",
      "Loading file: ./tmp/file7.p\n",
      "Loading file: ./tmp/file8.p\n"
     ]
    }
   ],
   "source": [
    "file_target_dir = \"./tmp/\"\n",
    "\n",
    "#Download files\n",
    "download_files_from_github(file_target_dir)\n",
    "#Load files and create dict\n",
    "word_dict = load_word2vecfiles(file_target_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076dc461-9041-4b81-8ef4-ef288602f87c",
   "metadata": {},
   "source": [
    "## cosine similarity\n",
    "- reflects the degree of similarity between two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2ab7f4f-d9c7-4b3e-a136-2a4797a57156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(u, v):\n",
    "    distance = 0.0\n",
    "    epsilon = 1e-10 # prevent deviding by 0\n",
    "    dot = np.dot(u.T, v)\n",
    "    # Compute the L2 norm of u & v\n",
    "    norm_u = np.sqrt(np.sum(u**2))\n",
    "    norm_v = np.sqrt(np.sum(v**2))\n",
    "    cosine_similarity = dot/((norm_u*norm_v)+epsilon)\n",
    "    return cosine_similarity    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eba7d6f-7972-4c30-baa2-01c87ee8d7d2",
   "metadata": {},
   "source": [
    "## most k similar\n",
    "- find the most similar word to the input word by calculating the cosine similarity between the word vector and the other word vectors and returning K most similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b77811b7-8b9c-4153-938c-b63e99da2d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_k_similar(word_in, word_dict,k=1):\n",
    "    words = word_dict.keys()\n",
    "    word_vec = word_dict[word_in]\n",
    "    most_similars_heap = [(-100, '') for _ in range(k)]\n",
    "    for w in words:\n",
    "        if w==word_in:\n",
    "            continue\n",
    "        cosine_sim = cosine_similarity(word_vec, word_dict[w])\n",
    "        heappushpop(most_similars_heap, (cosine_sim, w))\n",
    "    most_similars_tuples = [tup for tup in most_similars_heap]\n",
    "    _, best_words = zip(*most_similars_tuples)\n",
    "    return best_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410ef1b5-c335-4f83-8aca-e80e9b5dc66c",
   "metadata": {},
   "source": [
    "## doesn't match\n",
    "- takes a list of words and returns the word the doesnt match by comparing cousine similarities each word and all the other words and returning the words with the lowest score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8035a5b2-fa2b-441d-8a89-0b6ab36c2c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doesnt_match(words, word_dict):\n",
    "    dots_tot = []\n",
    "    for w in words:\n",
    "        dots = 0\n",
    "        for w2 in words:\n",
    "            if w2==w:\n",
    "                continue\n",
    "            v = word_dict[w]\n",
    "            u = word_dict[w2]\n",
    "            dots = dots + cosine_similarity(v, u)\n",
    "        dots.tot.append(dots)\n",
    "    return (words[np.argmin(dots_tot)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba80fdc5-80c9-4dbd-b76e-84d5ca3f64f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
